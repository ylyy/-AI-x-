{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "说明：checkpoint由于被覆盖了未保存\n",
    "\n",
    "数据集划分借鉴羽小濯的https://aistudio.baidu.com/aistudio/projectdetail/2145019?channelType=0&channel=0的工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压一下略小改之后的PaddleSeg，解压一次就可以注释掉了\r\n",
    "!unzip -oq /home/aistudio/PaddleSeg.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -qo data/data100087/B榜测试数据集.zip -d data/\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压数据集至data/目录\r\n",
    "!unzip -qo data/data95249/train_50k_mask.zip -d data/\r\n",
    "!unzip -oq data/data95249/train_image.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据集划分\n",
    "执行一次就行了，之后可直接跳到后面的参数配置及训练\n",
    "\n",
    "借鉴羽小濯的https://aistudio.baidu.com/aistudio/projectdetail/2145019?channelType=0&channel=0的工程，在此感谢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "import sys\r\n",
    "sys.path.append(\"PaddleSeg\")\r\n",
    "import paddleseg\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "from tqdm import tqdm\r\n",
    "import random\r\n",
    "#设置随机数种子\r\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_txt(file_name, imgs_path, labels_path=None, mode='train', val_pro=0.2):\r\n",
    "    assert mode==\"train\" or mode==\"test\", \"ERROR:mode must be train or test.\"\r\n",
    "    if mode!=\"test\":\r\n",
    "        train_path = []\r\n",
    "        for idx, f_path in enumerate(imgs_path):\r\n",
    "            for i_path in sorted(os.listdir(f_path)):\r\n",
    "                path1 = os.path.join(f_path, i_path) \r\n",
    "                path2 = os.path.join(labels_path[idx], i_path)\r\n",
    "                train_path.append((path1, path2, str(idx)))\r\n",
    "        \r\n",
    "        if val_pro>=0 and val_pro<=1:\r\n",
    "            #打乱数据\r\n",
    "            random.shuffle(train_path)\r\n",
    "            val_len = int(len(train_path)*val_pro)\r\n",
    "            val_path = train_path[:val_len]\r\n",
    "            train_path = train_path[val_len:]\r\n",
    "            with open(file_name[0], 'w') as f:\r\n",
    "                for path in train_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\")\r\n",
    "            with open(file_name[1], 'w') as f:\r\n",
    "                for path in val_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\")  \r\n",
    "            return len(train_path), val_len\r\n",
    "        else:\r\n",
    "            with open(file_name[0], 'w') as f:\r\n",
    "                for path in train_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\") \r\n",
    "            return len(train_path), 0\r\n",
    "    else:\r\n",
    "        with open(file_name, 'w') as f:\r\n",
    "            for path in imgs_path:\r\n",
    "                img_path = os.path.join(test_path, path)\r\n",
    "                f.write(img_path+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_txt(data_root, train_imgs_dir=None, train_labels_dir=None, test_dir=None, val_pro=0.2):\r\n",
    "    if train_imgs_dir is not None:\r\n",
    "        if os.path.exists(\"train.txt\"):\r\n",
    "            os.remove(\"train.txt\")\r\n",
    "        if os.path.exists(\"val.txt\"):\r\n",
    "            os.remove(\"val.txt\")\r\n",
    "        train_imgs_dir = os.path.join(data_root, train_imgs_dir)\r\n",
    "        train_labels_dir = os.path.join(data_root, train_labels_dir)\r\n",
    "        file_names = os.listdir(train_imgs_dir)\r\n",
    "        file_names = sorted(file_names)\r\n",
    "        train_imgs_path, train_labels_path =[], []\r\n",
    "        for na in file_names:\r\n",
    "            train_imgs_path.append(os.path.join(train_imgs_dir, na))\r\n",
    "            train_labels_path.append(os.path.join(train_labels_dir, na))\r\n",
    "        train_len, val_len = write_txt([\"train.txt\", \"val.txt\"], train_imgs_path, train_labels_path, mode='train', val_pro=val_pro)\r\n",
    "        \r\n",
    "        print(\"训练数据整理完毕！训练集长度：{}，验证集长度：{}， 类别数：{}\".format(train_len, val_len, len(file_names)))\r\n",
    "\r\n",
    "    if test_dir is not None:\r\n",
    "        if os.path.exists(\"test.txt\"):\r\n",
    "            os.remove(\"test.txt\")\r\n",
    "        global test_path\r\n",
    "        test_path = os.path.join(data_root, test_dir)\r\n",
    "        test_imgs_path_list = sorted(os.listdir(test_path))\r\n",
    "        write_txt(\"test.txt\", test_imgs_path_list, mode=\"test\")\r\n",
    "        print(\"测试数据整理完毕！测试集长度：{}\".format(len(test_imgs_path_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据整理完毕！训练集长度：40000，验证集长度：10000， 类别数：500\n",
      "测试数据整理完毕！测试集长度：10989\n"
     ]
    }
   ],
   "source": [
    "data_root = \"data\"\r\n",
    "train_imgs_dir = \"train_image\"\r\n",
    "train_labels_dir = \"train_50k_mask\"\r\n",
    "test_dir = \"test_image\"\r\n",
    "create_txt(data_root, train_imgs_dir, train_labels_dir, test_dir, val_pro=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 参数配置及训练\n",
    "本人使用了paddleseg套件，在此像其表示感谢。\n",
    "\n",
    "因为有paddle推出的高精度语义分割模型ocrnet，所以本人比赛中使用了此模型\n",
    "\n",
    "·在ocrnet.yml中修改参数配置，包括数据增广使用了paddleseg提供的transformer工具里的    \n",
    "\n",
    "\t- type: RandomHorizontalFlip\n",
    "    \n",
    "    - type: RandomVerticalFlip\n",
    "    \n",
    "    - type: RandomBlur       提高0.4%个精确度\n",
    "    \n",
    "    - type: ResizeStepScaling  \n",
    "    \n",
    "    - type: RandomDistort    提高0.4%个精确度\n",
    "    \n",
    "·输入图像大小被resize到【256,256】是因为图像太大运行速度特别慢，对提升精度也没有特别好的帮助\n",
    "\n",
    "·PolynomialDecay作为学习率衰减方式，0.03的学习率损失下降较快\n",
    "\n",
    "·使用Diceloss作为损失函数相比交叉熵损失更加接近IOU的评价标准，提高2%个精确度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-09 15:07:19 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.4.0-150-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
      "cudnn: 7.6\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: Tesla V100-SXM2-32GB']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddlePaddle: 2.1.0\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n",
      "2021-08-09 15:07:19 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 40\n",
      "iters: 30000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  - 0.4\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: DiceLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.03\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  backbone:\n",
      "    align_corners: false\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/hrnet_w48_ssld.tar.gz\n",
      "    type: HRNet_W48\n",
      "  backbone_indices:\n",
      "  - -1\n",
      "  pretrained: null\n",
      "  type: OCRNet\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: /home/aistudio/train.txt\n",
      "  transforms:\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomVerticalFlip\n",
      "  - type: RandomBlur\n",
      "  - max_scale_factor: 2.0\n",
      "    min_scale_factor: 0.5\n",
      "    scale_step_size: 0.25\n",
      "    type: ResizeStepScaling\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/val.txt\n",
      "------------------------------------------------\n",
      "W0809 15:07:20.263645  1279 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0809 15:07:20.263700  1279 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "2021-08-09 15:07:25 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/hrnet_w48_ssld.tar.gz\n",
      "2021-08-09 15:07:28 [INFO]\tThere are 1525/1525 variables loaded into HRNet.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"PaddleSeg/train.py\", line 190, in <module>\n",
      "    main(args)\n",
      "  File \"PaddleSeg/train.py\", line 185, in main\n",
      "    fp16=args.fp16)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/core/train.py\", line 180, in train\n",
      "    logits_list = model(images)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/ocrnet.py\", line 73, in forward\n",
      "    logit_list = self.head(feats)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/ocrnet.py\", line 134, in forward\n",
      "    ocr = self.spatial_ocr(pixels, object_regions)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/ocrnet.py\", line 192, in forward\n",
      "    feats = self.conv1x1(feats)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/container.py\", line 97, in forward\n",
      "    input = layer(input)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/layers/layer_libs.py\", line 51, in forward\n",
      "    x = self._conv(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/conv.py\", line 667, in forward\n",
      "    use_cudnn=self._use_cudnn)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/conv.py\", line 116, in _conv_nd\n",
      "    out = nn.elementwise_add(pre_bias, bias, axis=channel_dim)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 11554, in elementwise_add\n",
      "    use_mkldnn=core.globals()[\"FLAGS_use_mkldnn\"])\n",
      "  File \"<decorator-gen-29>\", line 2, in _elementwise_op_in_dygraph\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 225, in __impl__\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 205, in _elementwise_op_in_dygraph\n",
      "    out = op(x, y, 'axis', axis, 'use_mkldnn', use_mkldnn)\n",
      "SystemError: (Fatal) Operator elementwise_add raises an paddle::memory::allocation::BadAlloc exception.\n",
      "The exception content is\n",
      ":ResourceExhaustedError: \n",
      "\n",
      "Out of memory error on GPU 0. Cannot allocate 320.000244MB memory on GPU 0, 15.774996GB memory has been allocated and available memory is only 230.404037MB.\n",
      "\n",
      "Please check whether there is any other process using GPU 0.\n",
      "1. If yes, please stop them, or start PaddlePaddle on another GPU.\n",
      "2. If no, please decrease the batch size of your model. \n",
      "\n",
      " (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:79)\n",
      ". (at /paddle/paddle/fluid/imperative/tracer.cc:192)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python PaddleSeg/train.py --config ocrnet.yml --do_eval --use_vdl \\\r\n",
    "--save_dir /home/aistudio/output_ocrnet --save_interval 2000 \\\r\n",
    "                    # --resume_model /home/aistudio/output_ocrnet/iter_26000 \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 推理\n",
    "已在PaddleSeg中做了修改可以直接预测出结果\n",
    "最后在推理时使用数据增广可以提高预测精度，但是本人由于没来及提交更好的结果并没有体现到比赛成绩上，B榜分数为0.76425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#推理\r\n",
    "!python PaddleSeg/predict.py --config ocrnet.yml \\\r\n",
    "# --model_path output_ocrnet/best_model/model.pdparams \\\r\n",
    "--model_path model.pdparams\\    #该模型为较好的最终训练结果，checkpoint由于被覆盖了未保存\r\n",
    "--image_path data/test_image --save_dir output/result_1 --aug_pred --flip_horizontal --flip_vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 压缩结果，提交文件\n",
    "[第三届中国AI+创新创业大赛：半监督学习目标定位竞赛](https://aistudio.baidu.com/aistudio/competition/detail/78)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd output/result_1/results\r\n",
    "!zip -r -oq /home/aistudio/pred.zip ./\r\n",
    "%cd /home/aistudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
